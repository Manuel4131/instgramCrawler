For instagram:
    You need to use developer's API and they have strict constrains. If
    application to the developer's API is passed, you then can use these
    APIs to get the image. However, I think the queries might be very tiny.

    Well, but I have found a GREAT solution to hack it. Use 'selenium' to 
    press the links, saving them to a file. After reading the usl links in 
    the file, you can download the data, saving the images. 
    (I have already starred a repo@github)
    To directly get the whole page by using `requests` doesn't work at all.

For Google Search:
    Since the fucking term of use, they prevent users to use the web crawler 
    skill to crawl the data. Fuck off Google! Google collects the data without
    the original's permission and saving them as their properties, but not
    allowing users to get the data because they put lots of effort to collect
    the data...

    For Google Image Search:
        The python API `requests` works, but not totally. I always get the first 
    20 urls each time... Maybe `selenium` can hack it.

For others:
    I think `request` is very powerful. If it's combined well with xml, json,
    lxml, tree, re and other string parsing tools. Many sites' data can be
    collected just like what Google do. 


### Comment ####
For creating the hacking tools, you must be quipped
with abudant knowledge and excellent programming skill.

Well, to train the excellent programming skill is not 

as difficult as you think. 

You just have to write code solidly and fast.

That's really not hard!
